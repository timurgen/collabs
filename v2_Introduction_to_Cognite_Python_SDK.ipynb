{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v2 Introduction to Cognite Python SDK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timurgen/collabs/blob/main/v2_Introduction_to_Cognite_Python_SDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvTGHFbHUCqa"
      },
      "source": [
        "##Follow the Section Links to read the Cognite Learn content before running code examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sS9baFNCsJ4"
      },
      "source": [
        "##[1. Environment Set Up](https://cognite.talentlms.com/unit/view/id:2116)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8H5WYaDAgF"
      },
      "source": [
        "###Install the Cognite SDK package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnNKEbXHHH61"
      },
      "source": [
        "If you recieve the errors:\n",
        "\n",
        "`ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.`\n",
        "\n",
        "`ERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.`\n",
        "\n",
        "You can disregard them and do not need to click \"Restart Runtime\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyOeQPCeDGMV"
      },
      "source": [
        "!pip install \"cognite-sdk>=1.1.10\"\n",
        "!pip install --upgrade numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8i-1mQDDKhc"
      },
      "source": [
        "###Import other required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BjwC7qlDQP1"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from datetime import datetime\n",
        "from getpass import getpass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from cognite.client import CogniteClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFI6c51zEn_y"
      },
      "source": [
        "### Connect to Cognite Data Fusion\n",
        "This client object is how all queries will be sent to the Cognite API to retrieve data.\n",
        "\n",
        "When prompted for your API key, use the stored key generated previously in the course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_PcTGjREqN0"
      },
      "source": [
        "client = CogniteClient(api_key=getpass(\"Open Industrial Data API-KEY: \"),\n",
        "                       project=\"publicdata\", client_name=\"OID_example\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_C7QvUl1Mc"
      },
      "source": [
        "##[2. Retrieving Lists of Assets](https://cognite.talentlms.com/unit/view/id:2118)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ignb8US7l-Qv"
      },
      "source": [
        "###List assets\n",
        "The `client.assets.list(limit=20)` function retrieves the first `limit` assets, and returns it as an `AssetList`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBd_bxusmJoD"
      },
      "source": [
        "client.assets.list(limit=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBQDOD_8982K"
      },
      "source": [
        "##Search Assets##\n",
        "The `client.assets.search()` function allows you to search by a specific property of the asset, including its name, parent, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGzlTbUJmB8Z"
      },
      "source": [
        "###Fuzzy Search by name\n",
        "The search by name includes results that are similar in name, but not an exact match."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXZ4_aIhmLjd"
      },
      "source": [
        "asset_name = \"23-HA-9103\"\n",
        "assets = client.assets.search(name=asset_name)\n",
        "assets[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP1FgfPVmDMk"
      },
      "source": [
        "###Specific Search\n",
        "The `client.assets.retrieve()` interface provides the same information for one specific asset based on the provided ID or external ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVpjB6N9mN7U"
      },
      "source": [
        "asset_id = [a.id for a in assets if a.name==asset_name][0]\n",
        "client.assets.retrieve(id=asset_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOi5l9ArnH1c"
      },
      "source": [
        "##[3. Asset Hierarchy and Relationships](https://cognite.talentlms.com/unit/view/id:2124)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQbT4KIFnLBq"
      },
      "source": [
        "We will generate a list of all children of the main asset of interest. The main asset of interest is listed first, then the children are listed underneath in following rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aOeBcKYnRLE"
      },
      "source": [
        "subtree = client.assets.retrieve_subtree(id=asset_id)\n",
        "subtree[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIyYdejlnUtT"
      },
      "source": [
        "##[4. Collecting Time Series Data](https://cognite.talentlms.com/unit/view/id:2119)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt6Dcdn1rRS4"
      },
      "source": [
        "###Compile a list of time series objects under the asset\n",
        "For each of the assets in the subtree we retrieved, we get the associated time series objects and merge them into a single `TimeSeriesList` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOx8h90ArYY2"
      },
      "source": [
        "all_timeseries = subtree.time_series()\n",
        "print(len(all_timeseries),'time series in subtree')\n",
        "all_timeseries[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qllkrh6Dtp7R"
      },
      "source": [
        "If you are curious about which asset a time series is attached to, you can retrieve more information of the asset by using the retrieve function. Note that the property is called `asset_id` following typical python style, while `assetId` is used in the underlying API objects and tabular outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0afqCmxDtsAf"
      },
      "source": [
        "client.assets.retrieve(id=all_timeseries[0].asset_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdRhnDi-sN_9"
      },
      "source": [
        "###View datapoints for specific time series\n",
        "The identifier to retrieve Datapoints is the externalId column from the output above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j1bQ9Drtpxz"
      },
      "source": [
        "client.datapoints.retrieve(external_id=\"pi:160184\", start=\"10d-ago\", end=\"now\")[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnWqcSkLt5hq"
      },
      "source": [
        "##[5. Use Cases of CDF Data](https://cognite.talentlms.com/unit/view/id:2120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwpidXxYKoAl"
      },
      "source": [
        "###Collect datapoints from CDF\n",
        "The time series names are defined in the in_ts_exids and out_ts_exid lists below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9yTIu44uDEX"
      },
      "source": [
        "in_ts_exids = [\"pi:160182\", \"pi:160697\", \"pi:160882\"]\n",
        "out_ts_exid = \"pi:160696\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpqB2BA8Kw_T"
      },
      "source": [
        "###Retrieve Data Points from CDF\n",
        "Most object types in the Python SDK have a `to_pandas` method which converts the result to a pandas dataframe. For retrieving aggregates such as the average over each time period, you can use `client.datapoints.retrieve_dataframe` to get a pandas dataframe directly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH4rB1zbuOiZ"
      },
      "source": [
        "ts_exids = in_ts_exids + [out_ts_exid]\n",
        "\n",
        "train_start_date = datetime(2018, 8, 1)\n",
        "\n",
        "train_end_date = train_start_date + timedelta(days=30)\n",
        "\n",
        "datapoints_df = client.datapoints.retrieve_dataframe(external_id=ts_exids,\n",
        "                                                     aggregates=['average'],\n",
        "                                                     granularity='1m',\n",
        "                                                     start=train_start_date,\n",
        "                                                     end=train_end_date,\n",
        "                                                     include_aggregate_name=False\n",
        "                                                     )\n",
        "datapoints_df.fillna(method=\"ffill\", inplace=True)\n",
        "datapoints_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OhckFiVAUfO"
      },
      "source": [
        "There are also shortcuts for filling the dataframe when using interpolation or count aggregates. Note that without the `include_aggregate_name=False` option, the aggregate name is appended to the external id to form a unique column name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSBMHkzmuaSn"
      },
      "source": [
        "datapoints_df_interp = client.datapoints.retrieve_dataframe(external_id=ts_exids[0:2],\n",
        "                                                           aggregates=['interpolation','count'],\n",
        "                                                           granularity='1h',\n",
        "                                                           start=train_start_date,\n",
        "                                                           end=train_end_date,\n",
        "                                                           complete=\"fill\"\n",
        "                                                          )\n",
        "datapoints_df_interp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPO2NqAjGKIs"
      },
      "source": [
        "###Visualize the Time Series Data\n",
        "The bottom right plot is the output time series, while the other 3 are the inputs used to create an estimate for the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9CHHKVCuuUQ"
      },
      "source": [
        "cols = datapoints_df.columns\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
        "for i, col in enumerate(cols):\n",
        "    datapoints_df.loc[:, [col]].plot(ax=axes.ravel()[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pw7vLl1GWRY"
      },
      "source": [
        "##[6. Model Creation](https://cognite.talentlms.com/unit/view/id:2121)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P96_RImyHkfH"
      },
      "source": [
        "###Gathering Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svatSUcyu5Sf"
      },
      "source": [
        "train_X = datapoints_df[in_ts_exids].to_numpy()\n",
        "train_y = datapoints_df[out_ts_exid].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqWNjD3SKC-0"
      },
      "source": [
        "###Get a separate DataFrame from CDF\n",
        "The data which we will use to predict the output pressure will be stored in a seperate dataframe as collected below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4MUjhrBvLuI"
      },
      "source": [
        "predict_start_date = train_end_date\n",
        "# Make the prediction on 1 hour of data\n",
        "predict_end_date = train_end_date + timedelta(hours=1)\n",
        "predict_df = client.datapoints.retrieve_dataframe(\n",
        "    external_id=ts_exids,\n",
        "    aggregates=['average'],\n",
        "    granularity='1m',\n",
        "    start=predict_start_date,\n",
        "    end=predict_end_date,\n",
        "    include_aggregate_name=False\n",
        ")\n",
        "predict_df.fillna(method=\"ffill\", inplace = True)\n",
        "predict_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6K-LX0vPZL"
      },
      "source": [
        "cols = predict_df.columns\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
        "for i, col in enumerate(cols):\n",
        "    predict_df.plot(y=col, ax=axes.ravel()[i]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXJnaXAIKMzk"
      },
      "source": [
        "##[7. Linear Regression Model](https://cognite.talentlms.com/unit/view/id:2122)\n",
        "As a simple starting point we will check to see how a linear regression model performs to predict the output pressure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iDDP5hNKUHk"
      },
      "source": [
        "###Utilize sklearn to create a basic linear regression model\n",
        "Sklearn is common package utilized to import and deploy data science models. Linear Regression is only one of many options for constructing models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cdr9BNUKdAA"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X, train_y)\n",
        "\n",
        "X = predict_df[in_ts_exids].values\n",
        "predict_df[\"prediction_lin_reg1\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg1\"])\n",
        "r2_s = r2_score(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg1\"])\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our forecasts is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "predict_df.plot(y=[out_ts_exid, \"prediction_lin_reg1\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTQCGG7fKfG_"
      },
      "source": [
        "###Look at the fit for the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofxaIfbmKiSy"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X, train_y)\n",
        "\n",
        "X = datapoints_df[in_ts_exids].values\n",
        "datapoints_df[\"prediction_lin_reg1\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg1\"])\n",
        "r2_s = r2_score(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg1\"])\n",
        "print('The Mean Squared Error on the training data is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our training data is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "datapoints_df.plot(y=[out_ts_exid, \"prediction_lin_reg1\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-rzXGUzYcRo"
      },
      "source": [
        "###Add dummy variable for anomalous period"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ukJfdNjYgYS"
      },
      "source": [
        "datapoints_df['state'] = (datapoints_df[out_ts_exid]< 4)*1\n",
        "predict_df['state'] = (predict_df[out_ts_exid]< 4)*1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m83vWycgYh_P"
      },
      "source": [
        "train_X2 = datapoints_df[in_ts_exids + ['state']].values\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X2, train_y)\n",
        "X = predict_df[in_ts_exids + ['state']].values\n",
        "predict_df[\"prediction_lin_reg2\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg2\"])\n",
        "r2_s = r2_score(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg2\"])\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our forecasts is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "predict_df.plot(y=[out_ts_exid, \"prediction_lin_reg2\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZAe_bULYkXb"
      },
      "source": [
        "###Look at the fit for the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5enFBX2YnT4"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X2, train_y)\n",
        "\n",
        "X = datapoints_df[in_ts_exids + ['state']].values\n",
        "datapoints_df[\"prediction_lin_reg2\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(datapoints_df[out_ts_exid], datapoints_df[\"prediction_lin_reg2\"])\n",
        "r2_s = r2_score(datapoints_df[out_ts_exid], datapoints_df[\"prediction_lin_reg2\"])\n",
        "print('The Mean Squared Error on the training data is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our training data is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "datapoints_df.plot(y=[out_ts_exid, \"prediction_lin_reg2\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNwbnrwuYulj"
      },
      "source": [
        "###Remove Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZs5n82aYwR-"
      },
      "source": [
        "quantiles = [0.95, 0.975, 0.98, 0.99]\n",
        "quantiles_df = pd.DataFrame(\n",
        "    {\n",
        "        \"quantile\": quantiles,\n",
        "        \"value\": np.quantile(datapoints_df[out_ts_exid], q=quantiles),\n",
        "    }\n",
        ")\n",
        "quantiles_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0kT_ItYx0O"
      },
      "source": [
        "datapoints_df_adj = datapoints_df.loc[datapoints_df[out_ts_exid] < 4, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHs_K3xnYzFR"
      },
      "source": [
        "train_X_adj = datapoints_df_adj[in_ts_exids].values\n",
        "train_y_adj = datapoints_df_adj[out_ts_exid].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-EgHb7DY0ev"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X_adj, train_y_adj)\n",
        "\n",
        "X = predict_df[in_ts_exids].values\n",
        "predict_df[\"prediction_lin_reg3\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg3\"])\n",
        "r2_s = r2_score(predict_df[out_ts_exid], predict_df[\"prediction_lin_reg3\"])\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 6)))\n",
        "print('The R2 score of our forecasts is {}'.format(round(r2_s, 6)))\n",
        "\n",
        "predict_df.plot(y=[out_ts_exid, \"prediction_lin_reg3\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFhTEgRgY3Gb"
      },
      "source": [
        "###Look at the fit for the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q16y0WLlY6vJ"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(train_X_adj, train_y_adj)\n",
        "\n",
        "X = datapoints_df[in_ts_exids].values\n",
        "datapoints_df[\"prediction_lin_reg3\"] = lin_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(datapoints_df[out_ts_exid], datapoints_df[\"prediction_lin_reg3\"])\n",
        "r2_s = r2_score(datapoints_df[out_ts_exid], datapoints_df[\"prediction_lin_reg3\"])\n",
        "print('The Mean Squared Error on the training data is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our training data is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "datapoints_df.plot(y=[out_ts_exid, \"prediction_lin_reg3\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeKYxrlnZEn9"
      },
      "source": [
        "##[8. Random Forest Ensemble Model](https://cognite.talentlms.com/unit/view/id:2123)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaX9X8jZKkh"
      },
      "source": [
        "rnd_forest_reg = RandomForestRegressor(n_estimators=10, min_samples_split=20, max_depth=5)\n",
        "rnd_forest_reg.fit(train_X, train_y)\n",
        "\n",
        "X = predict_df[in_ts_exids].values\n",
        "predict_df[\"prediction_rnd_forest\"] = rnd_forest_reg.predict(X)\n",
        "\n",
        "# print out mse of the prediction\n",
        "mse = mean_squared_error(predict_df[out_ts_exid], predict_df[\"prediction_rnd_forest\"])\n",
        "r2_s = r2_score(predict_df[out_ts_exid], predict_df[\"prediction_rnd_forest\"])\n",
        "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 4)))\n",
        "print('The R2 score of our forecasts is {}'.format(round(r2_s, 4)))\n",
        "\n",
        "predict_df.plot(y=[out_ts_exid, \"prediction_rnd_forest\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUiShm2tZOCj"
      },
      "source": [
        "rnd_forest_reg = RandomForestRegressor(n_estimators=10, min_samples_split=20, max_depth=5)\n",
        "rnd_forest_reg.fit(train_X, train_y)\n",
        "\n",
        "X = datapoints_df[in_ts_exids].values\n",
        "datapoints_df[\"prediction_rnd_forest\"] = rnd_forest_reg.predict(X)\n",
        "\n",
        "datapoints_df.plot(y=[out_ts_exid, \"prediction_rnd_forest\"], figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZEEbTAmZTE8"
      },
      "source": [
        "###Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnYUwca4ZW15"
      },
      "source": [
        "#Train up until 100 timestamps before anomalous period\n",
        "datapoints_df = datapoints_df.assign(\n",
        "    datetime=datapoints_df.index\n",
        ").reset_index(drop=True)\n",
        "\n",
        "predict_start_index = min(datapoints_df[datapoints_df[out_ts_exid] > 5].index) - 100\n",
        "\n",
        "datapoints_df_ad = datapoints_df.loc[:predict_start_index, :]\n",
        "train_X = datapoints_df_ad[in_ts_exids].values\n",
        "train_y = datapoints_df_ad[out_ts_exid].values\n",
        "\n",
        "predict_df_ad = datapoints_df.loc[predict_start_index+1:, in_ts_exids + [out_ts_exid, \"datetime\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewEXv31bZYrI"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(datapoints_df_ad[\"datetime\"], datapoints_df_ad[out_ts_exid], label=\"train\")\n",
        "plt.plot(predict_df_ad[\"datetime\"], predict_df_ad[out_ts_exid], label=\"predict\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"datetime\")\n",
        "plt.title(out_ts_exid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKSwc5rZbcn"
      },
      "source": [
        "rnd_forest_reg = RandomForestRegressor(n_estimators=10, min_samples_split=20, max_depth=5)\n",
        "rnd_forest_reg.fit(train_X, train_y)\n",
        "\n",
        "X = predict_df_ad[in_ts_exids].values\n",
        "predict_df_ad[\"prediction_rnd_forest\"] = rnd_forest_reg.predict(X)\n",
        "predict_df_ad[\"residual\"] = np.abs(predict_df_ad[\"prediction_rnd_forest\"]-predict_df_ad[out_ts_exid])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RjYmdL0ZdCR"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
        "predict_df_ad.plot(\n",
        "    x=\"datetime\",\n",
        "    y=[out_ts_exid, \"prediction_rnd_forest\"],\n",
        "    figsize=(12,7),\n",
        "    ax=ax1, \n",
        "    color=[\"C1\", \"C2\"],\n",
        ");\n",
        "predict_df_ad.plot(\n",
        "    x=\"datetime\",\n",
        "    y=[\"residual\"],\n",
        "    figsize=(12,7),\n",
        "    ax=ax2,\n",
        "    color=\"C3\",\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8pfUalWxHdn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}